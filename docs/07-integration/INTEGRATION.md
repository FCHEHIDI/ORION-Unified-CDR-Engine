# ORION Integration Stack

Guide complet pour lancer et tester l'infrastructure compl√®te ORION.

## üöÄ D√©marrage rapide

### Pr√©requis

- Docker Engine 24.0+
- Docker Compose V2
- 16 GB RAM minimum
- 50 GB disque disponible

### Lancer la stack compl√®te

```bash
# Depuis la racine du projet
docker-compose up -d

# V√©rifier les services
docker-compose ps

# Voir les logs
docker-compose logs -f
```

### Arr√™t et nettoyage

```bash
# Arr√™ter proprement
docker-compose down

# Nettoyer volumes (‚ö†Ô∏è perte de donn√©es)
docker-compose down -v
```

## üì¶ Services d√©ploy√©s

| Service | Port(s) | URL | Credentials |
|---------|---------|-----|-------------|
| **Infrastructure** |
| Zookeeper | 2181 | - | - |
| Kafka | 9092, 9093 | - | - |
| ScyllaDB | 9042, 19042 | - | - |
| **Pipeline ORION** |
| Traffic Generator | 9200 | http://localhost:9200 | - |
| Ingestion | 8081 | http://localhost:8081 | - |
| Validation | 8082 | http://localhost:8082 | - |
| Normalization | 8083 | http://localhost:8083 | - |
| Enrichment | 8084 | http://localhost:8084 | - |
| Storage Hot | 8085 | http://localhost:8085 | - |
| **Observability** |
| Prometheus | 9090 | http://localhost:9090 | - |
| Grafana | 3000 | http://localhost:3000 | admin / orion2026 |

## üîç V√©rification du d√©ploiement

### 1. Health checks

```bash
# Tous les services
for port in 9200 8081 8082 8083 8084 8085; do
  echo "Port $port: $(curl -s http://localhost:$port/health)"
done

# Kafka topics
docker exec orion-kafka kafka-topics --list --bootstrap-server localhost:9092

# ScyllaDB
docker exec orion-scylladb cqlsh -e "DESCRIBE KEYSPACES;"
```

### 2. M√©triques Prometheus

```bash
# V√©rifier scrape targets
curl -s http://localhost:9090/api/v1/targets | jq '.data.activeTargets[] | {job: .labels.job, health: .health}'

# Query exemple: taux g√©n√©ration CDR
curl -s "http://localhost:9090/api/v1/query?query=rate(traffic_generator_cdr_generated_total[1m])" | jq
```

### 3. Grafana Dashboards

1. Ouvrir http://localhost:3000
2. Login: `admin` / `orion2026`
3. Naviguer: **Dashboards ‚Üí ORION**
4. Dashboards disponibles:
   - **Pipeline Overview**: Vue globale (throughput, latency, errors)
   - **Traffic Generator**: G√©n√©ration CDR + simulation

## üß™ Sc√©narios de test

### Test 1: Pipeline nominal

**Objectif**: V√©rifier flux complet sans erreurs

```bash
# 1. V√©rifier g√©n√©ration CDR
curl http://localhost:9200/metrics | grep traffic_generator_cdr_generated_total

# 2. V√©rifier pipeline (5 min)
# Grafana ‚Üí Overview ‚Üí tous les graphes doivent monter

# 3. Query ScyllaDB
docker exec -it orion-scylladb cqlsh -e "
  SELECT COUNT(*) FROM orion_cdr.unified_cdr;
  SELECT * FROM orion_cdr.unified_cdr LIMIT 5;
"
```

**R√©sultats attendus**:
- ‚úÖ 100 CDR/s g√©n√©r√©s
- ‚úÖ Latence p95 < 100ms par stage
- ‚úÖ Success rate > 95%
- ‚úÖ CDR visibles dans ScyllaDB

### Test 2: D√©tection fraude

**Objectif**: Valider alertes fraude

```bash
# 1. Consulter CDR frauduleux d√©tect√©s
curl http://localhost:8084/metrics | grep enrichment_fraud_detected_total

# 2. Query ScyllaDB pour risk_level HIGH
docker exec -it orion-scylladb cqlsh -e "
  SELECT imsi, risk_level, risk_score, fraud_reason 
  FROM orion_cdr.unified_cdr 
  WHERE risk_level = 'high' 
  ALLOW FILTERING;
"
```

**R√©sultats attendus**:
- ‚úÖ ~10% fraude d√©tect√©e (10 CDR/s)
- ‚úÖ `risk_level = 'high'` avec `risk_score >= 0.7`
- ‚úÖ `fraud_reason` non vide

### Test 3: Burst mode

**Objectif**: Tester scalabilit√© sous charge

```bash
# 1. Attendre burst automatique (toutes les 5 min)
# OU forcer burst via env var:
docker-compose exec orion-traffic-generator sh -c '
  export BURST_ENABLED=true
  export BURST_MULTIPLIER=10
  export GENERATION_RATE=500
'

# 2. Observer Grafana ‚Üí Overview ‚Üí Throughput
# Pic attendu: 5000 CDR/s (500 * 10) pendant 30s

# 3. V√©rifier latence reste stable
curl http://localhost:9090/api/v1/query?query=histogram_quantile(0.95,rate(storage_insert_latency_seconds_bucket[1m]))
```

**R√©sultats attendus**:
- ‚úÖ Pipeline absorbe 5000 CDR/s
- ‚úÖ Latence p95 < 500ms (acceptable sous burst)
- ‚úÖ Aucun service ne crash

### Test 4: R√©silience erreurs

**Objectif**: Valider retry et backoff

```bash
# 1. V√©rifier erreurs simul√©es
curl http://localhost:9200/metrics | grep traffic_generator_errors_total

# 2. V√©rifier retries
curl http://localhost:9200/metrics | grep traffic_generator_retries_total

# 3. Ratio retry/error doit √™tre > 1 (plusieurs tentatives)
```

**R√©sultats attendus**:
- ‚úÖ ~3% erreurs (3 CDR/s)
- ‚úÖ Retries > Errors (exponential backoff actif)
- ‚úÖ CDR finalement envoy√©s apr√®s retry

### Test 5: CDR malform√©s

**Objectif**: Valider rejet donn√©es invalides

```bash
# 1. V√©rifier CDR rejet√©s
curl http://localhost:8082/metrics | grep validation_invalid_cdr_total

# 2. Query Kafka topic rejected
docker exec orion-kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic cdr.rejected \
  --from-beginning \
  --max-messages 5

# 3. V√©rifier types d'erreurs
curl http://localhost:9200/metrics | grep traffic_generator_malformed_total
```

**R√©sultats attendus**:
- ‚úÖ ~2% CDR malform√©s (2 CDR/s)
- ‚úÖ Rout√©s vers `cdr.rejected`
- ‚úÖ Pas d'insertion dans ScyllaDB

## üìä Dashboards Grafana

### Pipeline Overview

**M√©triques cl√©s**:
- **Throughput**: CDR/s √† chaque √©tape (ingestion ‚Üí storage)
- **Latency p95**: Temps traitement par microservice
- **Error rate**: % erreurs par stage
- **Success rate**: % CDR compl√©tant le pipeline

**Alertes**:
- üî¥ Success rate < 90%
- üü° Latency p95 > 500ms
- üî¥ Error rate > 10%

### Traffic Generator

**M√©triques cl√©s**:
- **Generation rate**: CDR g√©n√©r√©s/s
- **Fraud rate**: % CDR frauduleux
- **Kafka latency**: Temps envoi vers Kafka
- **Retry rate**: Tentatives retry/s

## üêõ Troubleshooting

### Kafka unreachable

**Sympt√¥mes**: Services ne d√©marrent pas, logs "Kafka connection failed"

**Solutions**:
```bash
# V√©rifier Kafka
docker logs orion-kafka | tail -50

# Recr√©er topics
docker exec orion-kafka kafka-topics --create --topic cdr.raw.FR --bootstrap-server localhost:9092 --partitions 3
```

### ScyllaDB schema manquant

**Sympt√¥mes**: `storage-hot` crash avec "Keyspace not found"

**Solutions**:
```bash
# Init manuel schema
docker exec -it orion-scylladb cqlsh -e "
CREATE KEYSPACE IF NOT EXISTS orion_cdr 
WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};

CREATE TABLE IF NOT EXISTS orion_cdr.unified_cdr (
  cdr_id uuid PRIMARY KEY,
  imsi text,
  msisdn text,
  -- ... (voir orion-storage-hot/schema.cql)
);
"

# Restart storage
docker-compose restart orion-storage-hot
```

### Grafana dashboards vides

**Sympt√¥mes**: Grafana ne montre pas de donn√©es

**Solutions**:
```bash
# V√©rifier datasource Prometheus
curl http://localhost:3000/api/datasources

# Tester query manuelle
curl "http://localhost:9090/api/v1/query?query=up"

# Reload Grafana config
docker-compose restart grafana
```

### Out of memory

**Sympt√¥mes**: Services killed, `docker-compose ps` shows `Exited (137)`

**Solutions**:
```bash
# R√©duire consommation
# Dans docker-compose.yml, ajuster:
# - ScyllaDB: --memory 1G --smp 1
# - Kafka: KAFKA_HEAP_OPTS=-Xmx512M

# Augmenter Docker Desktop RAM
# Settings ‚Üí Resources ‚Üí Memory: 16 GB
```

## üîß Configuration avanc√©e

### Tuning performance

```yaml
# docker-compose.override.yml
services:
  orion-traffic-generator:
    environment:
      GENERATION_RATE: 500  # 5x d√©bit
      BURST_MULTIPLIER: 10   # Burst plus intense
  
  kafka:
    environment:
      KAFKA_NUM_PARTITIONS: 10  # Plus de parall√©lisme
```

### Monitoring custom

```yaml
# config/prometheus.yml
scrape_configs:
  - job_name: 'custom-app'
    static_configs:
      - targets: ['my-app:8080']
```

## üìö R√©f√©rences

- [Architecture ORION](../docs/02-architecture/architecture-globale.md)
- [Monitoring](../docs/05-deploiement/monitoring.md)
- [Traffic Generator](./orion-traffic-generator/README.md)
- [Docker Local](../docs/05-deploiement/docker-local.md)

## üö¶ Prochaines √©tapes

1. **Ex√©cuter Test 1-5**: Valider tous les sc√©narios
2. **Capturer screenshots**: Grafana dashboards pour d√©mo
3. **Enregistrer vid√©os**: Pipeline en action
4. **Benchmarks**: Mesurer limites scalabilit√©
5. **Production**: Adapter configs pour env r√©el
