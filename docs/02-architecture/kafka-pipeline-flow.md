# ðŸ”„ Kafka Pipeline Flow - ORION CDR Processing

## ðŸ“‹ Vue d'Ensemble

Ce document explique **pourquoi ORION Ã©crit plusieurs fois dans Kafka** tout au long du pipeline de traitement des CDR (Call Detail Records).

> **RÃ©ponse courte** : On n'Ã©crit pas "dans" Kafka, on Ã©crit "entre" chaque Ã©tape du pipeline via Kafka. C'est un pattern d'**Event-Driven Architecture** oÃ¹ Kafka agit comme **bus de communication asynchrone** entre microservices.

---

## ðŸ”„ Le Pipeline Complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw CDR Input  â”‚  â† DonnÃ©es brutes tÃ©lÃ©com (appels, SMS, data)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    ðŸ“¨ KAFKA #1
    Topic: cdr.raw.{country}
         â”‚ (fr, be, ma, tn, pl, eg, ci, sn, cm, mg)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ orion-validation    â”‚  â† Valide format & rÃ¨gles mÃ©tier
â”‚  â”œâ”€ Consumer        â”‚     Lit: cdr.raw.*
â”‚  â””â”€ Producer â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–º ðŸ“¨ KAFKA #2a: cdr.validated (âœ… Valid)
â”‚                     â”‚     ðŸ“¨ KAFKA #2b: cdr.rejected (âŒ Invalid)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ (CDR valides seulement)
         â–¼
    ðŸ“¨ KAFKA #2a
    Topic: cdr.validated
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ orion-normalization â”‚  â† Unifie formats multi-pays
â”‚  â”œâ”€ Consumer        â”‚     Lit: cdr.validated
â”‚  â””â”€ Producer â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–º ðŸ“¨ KAFKA #3: cdr.normalized
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    ðŸ“¨ KAFKA #3
    Topic: cdr.normalized
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ orion-enrichment    â”‚  â† Ajoute fraud, network, client info
â”‚  â”œâ”€ Consumer        â”‚     Lit: cdr.normalized
â”‚  â””â”€ Producer â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–º ðŸ“¨ KAFKA #4: cdr.enriched
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    ðŸ“¨ KAFKA #4
    Topic: cdr.enriched
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€ï¿½ï¿½â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ orion-storage-hot   â”‚  â† Stockage ScyllaDB (pas de producer Kafka)
â”‚  â””â”€ Consumer        â”‚     Lit: cdr.enriched
â”‚                     â”‚     Ã‰crit: ScyllaDB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RÃ‰SULTAT : 4 Ã©critures Kafka + 1 lecture finale = 5 Ã©tapes
```

---

## ðŸ“ Exemples de Code dans ORION

### 1ï¸âƒ£ orion-validation â†’ Kafka (validated & rejected)

**Fichier** : `orion-validation/src/service/kafka_producer.rs`

```rust
impl KafkaProducerService {
    // âœ… Ã‰crit les CDR VALIDES
    pub async fn send_valid(&self, cdr: &ValidatedCDR) -> Result<()> {
        let record = FutureRecord::to(&self.output_topic)  // cdr.validated
            .key(cdr.cdr_id.as_bytes())
            .payload(&payload);
        
        self.producer.send(record, Timeout::After(Duration::from_secs(5))).await?;
        info!("Sent valid CDR {} to {}", cdr.cdr_id, self.output_topic);
    }
    
    // âŒ Ã‰crit les CDR REJETÃ‰S (Dead Letter Queue)
    pub async fn send_rejected(&self, error: &ValidationError) -> Result<()> {
        let record = FutureRecord::to(&self.rejected_topic)  // cdr.rejected
            .key(error.timestamp.as_bytes())
            .payload(&payload);
        
        self.producer.send(record, Timeout::After(Duration::from_secs(5))).await?;
        info!("Sent rejected CDR to {}", self.rejected_topic);
    }
}
```

**Pourquoi 2 topics ?**
- âœ… **SÃ©paration des flux** : CDR valides vs invalides
- âœ… **Dead Letter Queue (DLQ)** : Les erreurs ne polluent pas le pipeline principal
- âœ… **TraÃ§abilitÃ©** : Audit des rejets pour amÃ©liorer la qualitÃ© source
- âœ… **Reprocessing** : PossibilitÃ© de rejouer les rejets aprÃ¨s correction

---

### 2ï¸âƒ£ orion-normalization â†’ Kafka (normalized)

**Fichier** : `orion-normalization/src/service/kafka_producer.rs`

```rust
impl KafkaProducerService {
    pub async fn send(&self, cdr: &UnifiedCDR) -> Result<()> {
        let record = FutureRecord::to(&self.output_topic)  // cdr.normalized
            .key(cdr.cdr_id.as_bytes())
            .payload(&payload);
        
        self.producer.send(record, Timeout::After(Duration::from_secs(5))).await?;
        info!("Sent normalized CDR {} to {}", cdr.cdr_id, self.output_topic);
    }
}
```

**Pourquoi normaliser dans Kafka ?**
- âœ… **Format unifiÃ©** : 1 schÃ©ma pour tous les pays (France, Belgique, Maroc, Tunisie, etc.)
- âœ… **DÃ©couplage** : orion-enrichment ne connaÃ®t pas les formats raw spÃ©cifiques
- âœ… **Ã‰volutivitÃ©** : Ajout facile de nouveaux pays sans modifier enrichment
- âœ… **Replay** : Re-normalisation si les rÃ¨gles de mapping changent

---

### 3ï¸âƒ£ orion-enrichment â†’ Kafka (enriched)

**Fichier** : `orion-enrichment/src/service/kafka_producer.rs`

```rust
impl KafkaProducerService {
    pub async fn send(&self, cdr: &EnrichedCDR) -> Result<()> {
        let record = FutureRecord::to(&self.output_topic)  // cdr.enriched
            .key(cdr.unified.cdr_id.as_bytes())
            .payload(&payload);
        
        self.producer.send(record, Timeout::After(Duration::from_secs(5))).await?;
        info!("Sent enriched CDR {} to {}", cdr.unified.cdr_id, self.output_topic);
    }
}
```

**Pourquoi enrichir dans Kafka ?**
- âœ… **DonnÃ©es complÃ¨tes** : Fraud detection, network info, client profiling
- âœ… **Multi-consumers** : Storage, analytics, alerting peuvent tous consommer
- âœ… **Backpressure** : ScyllaDB peut Ãªtre lent, Kafka bufferise
- âœ… **Audit trail** : Historique complet de l'enrichissement

---

### 4ï¸âƒ£ orion-storage-hot â†’ ScyllaDB (fin du pipeline)

**Fichier** : `orion-storage-hot/src/service/kafka_consumer.rs`

```rust
impl KafkaConsumerService {
    pub async fn run(self) -> Result<()> {
        loop {
            match self.consumer.recv().await {
                Ok(message) => {
                    let enriched_cdr: EnrichedCDR = serde_json::from_slice(message.payload())?;
                    
                    // âœ… Ã‰criture finale dans ScyllaDB (PAS de producer Kafka)
                    self.storage.insert_cdr(&enriched_cdr).await?;
                    
                    info!("Stored CDR {} in ScyllaDB", enriched_cdr.unified.cdr_id);
                }
                Err(e) => error!("Kafka consumer error: {:?}", e),
            }
        }
    }
}
```

**Fin du pipeline** : Les donnÃ©es sont maintenant persistÃ©es dans ScyllaDB.

---

## ðŸŽ¯ Les 7 Raisons ClÃ©s

### 1. **DÃ©couplage des Services**
Chaque service est **indÃ©pendant** et peut Ã©voluer/redÃ©marrer sans affecter les autres.

```
Si orion-normalization crash â†’ orion-validation continue Ã  Ã©crire dans Kafka
Les messages attendent dans cdr.validated jusqu'au redÃ©marrage
```

### 2. **ScalabilitÃ© Horizontale**
On peut scaler chaque Ã©tape indÃ©pendamment selon les besoins.

```
Validation rapide (1 instance) â†’ Enrichment lent (5 instances)
Kafka distribue automatiquement la charge via partitions
```

### 3. **Replay & Reprocessing**
On peut rejouer le pipeline Ã  partir de n'importe quelle Ã©tape.

```
Bug dans enrichment dÃ©tectÃ© ?
â†’ Fix le code
â†’ Reset consumer offset sur cdr.normalized
â†’ Reprocesse tous les CDR depuis normalization
```

### 4. **TolÃ©rance aux Pannes**
Si un service crash, les messages restent dans Kafka (at-least-once delivery).

```
orion-storage-hot down pour maintenance ?
â†’ cdr.enriched accumule les messages
â†’ Au redÃ©marrage, tout est retraitÃ© automatiquement
```

### 5. **Monitoring & ObservabilitÃ©**
Chaque topic = point de mesure du pipeline.

```yaml
MÃ©triques Prometheus:
  - kafka_consumer_lag{topic="cdr.normalized"}   # Retard normalization
  - kafka_consumer_lag{topic="cdr.enriched"}     # Retard enrichment
  - orion_kafka_errors_total{service="validation"} # Erreurs par service

Alertes:
  - Lag > 1 minute â†’ Bottleneck dÃ©tectÃ©
  - Error rate > 1% â†’ ProblÃ¨me de qualitÃ© donnÃ©es
```

### 6. **SÃ©paration des Flux (Success vs Errors)**
Dead Letter Queue (DLQ) pour isoler les erreurs.

```
cdr.validated â†’ CDR valides (95%)
cdr.rejected  â†’ CDR invalides (5%, sÃ©parÃ©s pour analyse)
```

### 7. **Multi-Consumers Pattern**
Plusieurs services peuvent consommer le mÃªme topic (fan-out).

```
cdr.enriched est lu par:
  â”œâ”€ orion-storage-hot (ScyllaDB)    â† PrioritÃ© 1
  â”œâ”€ orion-analytics (future)        â† Analyse temps rÃ©el
  â”œâ”€ orion-alerting (future)         â† Alertes fraud
  â””â”€ orion-export-s3 (future)        â† Archivage cold storage
```

---

## ðŸ“Š Topologie Kafka ComplÃ¨te

### Topics et RÃ©tention

| Topic | Partitions | Retention | Raison |
|-------|-----------|-----------|--------|
| `cdr.raw.fr` | 10 | 7 jours | Replay en cas d'erreur ingestion |
| `cdr.raw.be` | 5 | 7 jours | Moins de volume que France |
| `cdr.raw.ma` | 8 | 7 jours | Maroc (volume moyen) |
| `cdr.validated` | 20 | 3 jours | Buffer validation â†’ normalization |
| `cdr.rejected` | 5 | 30 jours | **DLQ** : debug & retraitement |
| `cdr.normalized` | 20 | 3 jours | Buffer normalization â†’ enrichment |
| `cdr.enriched` | 30 | 1 jour | Buffer enrichment â†’ storage |

**Total topics** : ~15 (10 pays Ã— raw + 4 stages)

### Configuration Production

**Broker config** (voir `adr-004-kafka-multi-pays.md`) :
```properties
# Performance
num.network.threads=8
num.io.threads=16

# DurabilitÃ©
default.replication.factor=3
min.insync.replicas=2
unclean.leader.election.enable=false

# Compression
compression.type=snappy
```

**Producer config** (Rust) :
```toml
acks = "all"              # DurabilitÃ© max
compression.type = "snappy"
batch.size = 16384
linger.ms = 10
retries = 2147483647
```

**Consumer config** (Rust) :
```toml
auto.offset.reset = "earliest"
enable.auto.commit = false    # Manual commit
max.poll.records = 500
session.timeout.ms = 30000
```

---

## ðŸŽ“ FAQ Entretien

### Q: "Pourquoi pas une seule Ã©criture Kafka Ã  la fin ?"

> **RÃ©ponse** : On perdrait la rÃ©silience et le replay granulaire. Si enrichment crash aprÃ¨s avoir traitÃ© 1M CDR, on devrait tout refaire depuis le dÃ©but au lieu de juste rejouer depuis `cdr.normalized`.

### Q: "Quel est le coÃ»t de ces Ã©critures multiples ?"

> **RÃ©ponse** : 
> - **Latency** : ~5-10ms par write Kafka â†’ ~30-40ms total pour le pipeline
> - **Stockage** : Kafka a une rÃ©tention courte (1-7 jours), donnÃ©es finales dans ScyllaDB
> - **RÃ©seau** : Compression snappy â†’ ~50% rÃ©duction de bande passante
> - **ROI** : Le gain en rÃ©silience, scalabilitÃ© et observabilitÃ© compense largement

### Q: "Et la duplication de donnÃ©es ?"

> **RÃ©ponse** : 
> - Kafka = **buffer temporaire** (1-7 jours)
> - ScyllaDB = **storage permanent** (annÃ©es)
> - CoÃ»t Kafka nÃ©gligeable vs bÃ©nÃ©fices (replay, multi-consumers, dÃ©couplage)

### Q: "Comment gÃ©rez-vous l'ordre des messages ?"

> **RÃ©ponse** :
> - Partitionnement par `cdr_id` (key Kafka)
> - Garantie d'ordre **par partition**
> - Consumer group pour parallÃ©lisme sans duplication

### Q: "Que se passe-t-il si Kafka tombe ?"

> **RÃ©ponse** :
> - **RÃ©plication** : 3 brokers, min.insync.replicas=2
> - **Haute disponibilitÃ©** : Cluster multi-AZ
> - **Graceful degradation** : Services bufferisent localement si nÃ©cessaire
> - **Monitoring** : Alertes Prometheus + PagerDuty

---

## ðŸ“ˆ MÃ©triques & Monitoring

### Dashboards Grafana

```promql
# Throughput par topic
rate(kafka_server_brokertopicmetrics_messagesin_total{topic="cdr.enriched"}[1m])

# Consumer lag (critique !)
kafka_consumergroup_lag{group="orion-storage-hot", topic="cdr.enriched"}

# Latency end-to-end
histogram_quantile(0.99, 
  rate(orion_pipeline_duration_seconds_bucket[5m])
)

# Error rate
rate(orion_kafka_errors_total[1m]) / rate(orion_cdr_processed_total[1m])
```

### Alertes

```yaml
- alert: KafkaConsumerLagHigh
  expr: kafka_consumergroup_lag > 10000
  for: 5m
  annotations:
    summary: "Consumer {{ $labels.group }} lagging on {{ $labels.topic }}"

- alert: KafkaErrorRateHigh
  expr: rate(orion_kafka_errors_total[5m]) > 0.01  # 1%
  for: 2m
  annotations:
    summary: "High error rate in {{ $labels.service }}"
```

---

## ðŸ”§ Commandes Utiles

### VÃ©rifier le lag d'un consumer group
```bash
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --group orion-enrichment \
  --describe
```

### Compter les messages dans un topic
```bash
kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic cdr.enriched \
  --time -1
```

### Reset offset pour replay
```bash
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --group orion-storage-hot \
  --topic cdr.enriched \
  --reset-offsets --to-earliest \
  --execute
```

### Consommer les derniers messages (debug)
```bash
kcat -C -b localhost:9092 -t cdr.enriched -o -10 -f '%k: %s\n'
```

---

## ðŸ“š RÃ©fÃ©rences

- [ADR-004 : Kafka Multi-Pays](./decisions/adr-004-kafka-multi-pays.md)
- [Architecture Globale](./architecture-globale.md)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [rdkafka Rust Client](https://github.com/fede1024/rust-rdkafka)

---

**Auteur** : Architecture Team  
**Date** : 2026-02-19  
**Version** : 1.0  
**Status** : âœ… Production

---

## ðŸ’¡ RÃ©sumÃ© pour Entretien

**Question** : *"Pourquoi on retourne vers Kafka plusieurs fois ?"*

**RÃ©ponse concise** :

> "Dans ORION, on utilise Kafka comme **bus de communication asynchrone** entre chaque Ã©tape du pipeline de traitement des CDR.
> 
> On a **4 Ã©critures Kafka** :
> 1. **Validation** â†’ `cdr.validated` (âœ…) + `cdr.rejected` (âŒ DLQ)
> 2. **Normalization** â†’ `cdr.normalized` (format unifiÃ©)
> 3. **Enrichment** â†’ `cdr.enriched` (fraud + network + client)
> 4. **Storage** â†’ ScyllaDB (fin du pipeline)
> 
> **BÃ©nÃ©fices** :
> - âœ… **DÃ©couplage** : chaque service scale indÃ©pendamment
> - âœ… **RÃ©silience** : at-least-once delivery, replay possible
> - âœ… **ObservabilitÃ©** : monitoring du lag par Ã©tape
> - âœ… **Multi-consumers** : analytics, alerting peuvent s'abonner
> 
> C'est un pattern d'**Event-Driven Architecture** qui nous permet de traiter **100k+ CDR/sec** avec une latency P99 < 500ms.
